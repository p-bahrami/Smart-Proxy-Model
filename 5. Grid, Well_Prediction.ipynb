{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Imports<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>inputs<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 108 \n",
    "ny = 100\n",
    "nz = 63\n",
    "nt = nx * ny * nz\n",
    "\n",
    "n_models = 20\n",
    "\n",
    "\n",
    "#               14    12    15c   11B    1C\n",
    "#x = np.array([[1873, 3389, 3614, 4532, 1528]])   # BT1\n",
    "x = np.array([[308, 2605, 4782,  4399, 4149]])   # BT2\n",
    "#x = np.array([[3720, 273,  4777, 1937, 2257]])   # BT3\n",
    "#x = np.array([[2719, 2845, 4478, 3971, 1846]])   # BT4\n",
    "#x = np.array([[4965, 568,  779, 4472, 4494 ]])   # BT5\n",
    "\n",
    "df_lhs = pd.DataFrame(np.tile(x,(n_models,1)))   # 5 is the number of wells\n",
    "df_lhs.columns = [\"pf11b_rates\", \"pf12_rates\", \"pf14_rates\", \"pf1c_rates\", \"pf15c_rates\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Functions<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "def plot_examples(colormaps, data, min_leg, max_leg):\n",
    "    \n",
    "    n = len(colormaps)\n",
    "    fig, axs = plt.subplots(figsize=(9, 3), constrained_layout=True, squeeze=False)\n",
    "    \n",
    "    for [ax, cmap] in zip(axs.flat, colormaps):\n",
    "        psm = ax.pcolormesh(data, cmap=cmap, rasterized=True, vmin=min_leg, vmax=max_leg, edgecolor = 'lightgrey', linewidth = 0.005)\n",
    "        fig.colorbar(psm, ax=ax)\n",
    "        \n",
    "    plt.xlim([5, 75])   # limit the axis range\n",
    "    plt.ylim([0, 20])\n",
    "    plt.axis('off')    # remove the axis title\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to read the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading the text files and extracting the numbers\n",
    "def splitter(file):\n",
    "    import re\n",
    "    lines = file.readlines()\n",
    "    B = [x for x in lines if not x.startswith('--')]\n",
    "    C = \" \".join(B)\n",
    "    nums = []\n",
    "    #                  3*4.52            4*0            0\\n          4.235e-10 or 4.235E-10       5e-10 or 5E-10 \n",
    "    for n in re.findall(r'\\d+\\*\\d+\\.\\d+|\\d+\\*\\d+|[0]\\ |[0]\\n|\\d+\\.\\d+(?:e[+-]\\d+|E[-+]\\d+)?|\\d+(?:e[+-]\\d+|E[-+]\\d+)?', C):                 \n",
    "        split_by_ast = n.split(\"*\")\n",
    "        if len(split_by_ast) == 1:\n",
    "            nums += [float(split_by_ast[0])]\n",
    "        else:\n",
    "            nums += [float(split_by_ast[1])] * int(split_by_ast[0])\n",
    "    return nums\n",
    "\n",
    "\n",
    "# defining a function to get the text file and expand it\n",
    "\n",
    "def split(a):\n",
    "    import numpy as np\n",
    "    b = a.readlines()\n",
    "    c = [x.replace('\\n','') for x in b]\n",
    "    d = [j for i in c for j in i.split()]\n",
    "    e=[]\n",
    "    for i in d:\n",
    "        if \"*\" in i:\n",
    "            a=[i.split(\"*\")[1]]*int(i.split(\"*\")[0])\n",
    "            e.extend(a)\n",
    "        else:\n",
    "            e.append(i)\n",
    "    f = np.array(e)\n",
    "    g = [float(numeric_string) for numeric_string in f]\n",
    "    h = np.array(g)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below cell is for forcing the output cell from autoscrolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Outputs at different timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680400, 20)\n",
      "[[  0.       0.       0.       0.       0.       0.       0.       0.\n",
      "    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "    0.       0.       0.       0.    ]\n",
      " [  0.       0.       0.       0.       0.       0.       0.       0.\n",
      "    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "    0.       0.       0.       0.    ]\n",
      " [365.9641 370.2347 371.9886 373.0302 373.8159 374.4292 374.9714 375.4325\n",
      "  375.8167 376.1626 376.4686 376.7594 377.0198 377.263  377.4837 377.689\n",
      "  377.8863 378.0617 378.2252 378.3854]\n",
      " [364.6782 368.8883 370.5898 371.6252 372.4077 373.0199 373.5593 374.0227\n",
      "  374.408  374.7538 375.0599 375.351  375.6118 375.8552 376.0762 376.2817\n",
      "  376.4792 376.6548 376.8185 376.979 ]\n",
      " [364.9879 369.2021 370.9065 371.9402 372.7183 373.3283 373.867  374.33\n",
      "  374.7147 375.0598 375.366  375.6576 375.9187 376.1626 376.3838 376.5896\n",
      "  376.7873 376.9633 377.1272 377.2879]]\n"
     ]
    }
   ],
   "source": [
    "a = open('C:/Users/pymnb/Downloads/VOLVE/15/features/001.soil.for.location.txt', 'r')\n",
    "\n",
    "SOIL = np.array(splitter(a)).reshape((nt, 1), order='F')\n",
    "SOIL[SOIL < 0.053] = 0\n",
    "\n",
    "#removing a few grids where they were out of the main reservoir in VOLVE field\n",
    "indices = [554377, 565177, 575977, 576085, 586777, 586885, 597577, 597685, 608377, 608485, 619177,\\\n",
    "619285, 629977, 630085, 640777, 640885, 651577, 651685, 662377, 662485, 673177, 673285]\n",
    "\n",
    "SOIL[indices]=0\n",
    "actives = np.where(SOIL!=0)[0]\n",
    "\n",
    "non_actives = np.delete(np.arange(1,nt+1), actives)\n",
    "\n",
    "textfile_SO = open('C:/Users/pymnb/Downloads/VOLVE/15/features/bt2_SO.txt','r')\n",
    "textfile_P  = open('C:/Users/pymnb/Downloads/VOLVE/15/features/bt2_P.txt','r')\n",
    "\n",
    "SO_real = np.array(splitter(textfile_SO)).reshape((nx*ny*nz, n_models), order='F')\n",
    "print(SO_real.shape)\n",
    "P_real  = np.array(splitter(textfile_P)).reshape((nx*ny*nz, n_models), order='F')\n",
    "\n",
    "#SO_real[non_actives-1] = 0\n",
    "#P_real[non_actives-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Layer = 1\n",
    "\n",
    "for i in range(0,n_models):\n",
    "    SO_t = SO_real[:,i].reshape((nx*ny,nz), order='F')\n",
    "    SO_L = SO_t[:, (Layer-1):Layer]\n",
    "    TT = SO_L.reshape((nx, ny), order ='F')\n",
    "    \n",
    "    col_type = cm.get_cmap('rainbow', 256)\n",
    "    newcolors = col_type(np.linspace(0, 1, 1000))\n",
    "    #white = np.array([1, 1, 1, 1])\n",
    "    #newcolors[:1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "    #print('Timestep '+str(i+1))\n",
    "    #plot_examples([col_type, newcmp], TT, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Layer = 1\n",
    "\n",
    "for i in range(0,n_models):\n",
    "    P_t = P_real[:,i].reshape((nx*ny,nz), order='F')\n",
    "    P_L = P_t[:, (Layer-1):Layer]\n",
    "    RR = P_L.reshape((nx, ny), order ='F')\n",
    "    \n",
    "    col_type = cm.get_cmap('rainbow', 256)\n",
    "    newcolors = col_type(np.linspace(0, 1, 1000))\n",
    "    #white = np.array([1, 1, 1, 1])\n",
    "    #newcolors[:1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "    #print('Timestep '+str(i+1))\n",
    "    #plot_examples([col_type, newcmp], RR, 180, 280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of input for the CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "No_lhs = 5\n",
    "\n",
    "seg_statics_SO =  pd.read_csv('C:/Users/pymnb/Downloads/VOLVE/15/seg_statics_SO.csv', header = None)\n",
    "seg_statics_P =  pd.read_csv('C:/Users/pymnb/Downloads/VOLVE/15/seg_statics_P.csv', header = None)\n",
    "min_max_SO = np.array(pd.read_csv('C:/Users/pymnb/Downloads/VOLVE/15/min_max_SO.csv', header = None)).transpose()\n",
    "min_max_P = np.array(pd.read_csv('C:/Users/pymnb/Downloads/VOLVE/15/min_max_P.csv', header = None)).transpose()\n",
    "\n",
    "# Normalize the belind test\n",
    "X = np.repeat(x, actives.shape[0], axis=0)\n",
    "ranges = np.array([[0,5000],[0,5000],[0,5000],[0,5000],[0,5000]])\n",
    "\n",
    "Z = np.zeros((actives.shape[0],1))\n",
    "for i in range(0, No_lhs):\n",
    "    norm = np.array((X[:,i]-ranges[i,0])/(ranges[i,1]-ranges[i,0])).reshape(actives.shape[0],1)\n",
    "    norm_btest = np.concatenate([Z, norm], axis=1)\n",
    "    Z = norm_btest\n",
    "\n",
    "input_data_SO = np.concatenate([seg_statics_SO, Z[:,1:(No_lhs+1)]], axis=1)\n",
    "input_data_P = np.concatenate([seg_statics_P, Z[:,1:(No_lhs+1)]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Grid models (SO & P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time: 3.299452100000053 Sec\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "\n",
    "m = {}\n",
    "n = {}\n",
    "\n",
    "for s in range(1,n_models+1):\n",
    "    m['m'+str(s)] = load_model('C:/Users/pymnb/Downloads/VOLVE/15/Grid models/model_CNN_SO'+str(s)+'.h5')\n",
    "    n['n'+str(s)] = load_model('C:/Users/pymnb/Downloads/VOLVE/15/Grid models/model_CNN_P'+str(s)+'.h5')\n",
    "\n",
    "end = timer()\n",
    "print(\"Run Time: \"+str((end - start))+\" Sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict, and merge the results with inactive grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time: 79.81178519999958 Sec\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "O1 = np.zeros((actives.shape[0],1))\n",
    "O2 = np.zeros((actives.shape[0],1))\n",
    "Z1 = np.zeros((nt, 1))\n",
    "Z2 = np.zeros((nt, 1))\n",
    "\n",
    "for s in range(1,n_models+1):\n",
    "    \n",
    "    ypred_norm_SO = m['m'+str(s)].predict(input_data_SO.reshape(input_data_SO.shape[0], 31, 1))\n",
    "    ypred_SO = ypred_norm_SO*(1-0)+0\n",
    "    ypred_P = n['n'+str(s)].predict(input_data_P.reshape(input_data_P.shape[0], 31, 1))\n",
    "#------------------------------------------ for error histogram --------------------------------------------    \n",
    "    SOp = np.concatenate([O1, ypred_SO], axis=1)\n",
    "    Pp  = np.concatenate([O2, ypred_P],  axis=1)\n",
    "\n",
    "    O1 = SOp\n",
    "    O2 = Pp\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Merge the active and inactive grids\n",
    "    \n",
    "    A = np.zeros((nt, 1))\n",
    "    B = np.zeros((nt, 1))\n",
    "    \n",
    "    actives_r = actives.astype(np.int64)\n",
    "\n",
    "    for (i, j) in zip(actives, ypred_SO):\n",
    "        A[i] = j\n",
    "    \n",
    "    for (i, j) in zip(actives, ypred_P):\n",
    "        B[i] = j\n",
    "        \n",
    "    SOO = np.concatenate([Z1, A], axis = 1)\n",
    "    PP  = np.concatenate([Z2, B], axis = 1)\n",
    "    Z1 = SOO\n",
    "    Z2 = PP\n",
    "\n",
    "SOf = SOO[:,1:n_models+1]\n",
    "Pf  =  PP[:,1:n_models+1]\n",
    "#pd.DataFrame(Pf).to_csv('C:/Users/pymnb/Downloads/WAG Case/15/test2.csv', index=False,  header=None)\n",
    "#------------------------------------------------ for error histogram -----------------------------------\n",
    "SOpred = O1[:, 1:n_models+1]\n",
    "Ppred  = O2[:, 1:n_models+1]\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "end = timer()\n",
    "print(\"Run Time: \"+str((end - start))+\" Sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Output at different timesteps for SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 1\n",
      "Timestep 2\n",
      "Timestep 3\n",
      "Timestep 4\n",
      "Timestep 5\n",
      "Timestep 6\n",
      "Timestep 7\n",
      "Timestep 8\n",
      "Timestep 9\n",
      "Timestep 10\n",
      "Timestep 11\n",
      "Timestep 12\n",
      "Timestep 13\n",
      "Timestep 14\n",
      "Timestep 15\n",
      "Timestep 16\n",
      "Timestep 17\n",
      "Timestep 18\n",
      "Timestep 19\n",
      "Timestep 20\n"
     ]
    }
   ],
   "source": [
    "Layer=1\n",
    "\n",
    "for i in range(0,n_models):\n",
    "    SOg = SOf\n",
    "    SO_t = SOg[:,i].reshape((nx*ny,nz), order='F')\n",
    "    SO_L = SO_t[:, (Layer-1):Layer]\n",
    "    TT = SO_L.reshape((nx,ny), order ='F')\n",
    "    \n",
    "    col_type = cm.get_cmap('rainbow', 256)\n",
    "    newcolors = col_type(np.linspace(0, 1, 1000))\n",
    "    white = np.array([1, 1, 1, 1])\n",
    "    newcolors[:1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "    print('Timestep '+str(i+1))\n",
    "    #plot_examples([col_type, newcmp], TT, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the difference at different timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.971565,   RMSE: 0.000454\n",
      "R2: 0.961198,   RMSE: 0.000600\n",
      "R2: 0.951882,   RMSE: 0.000728\n",
      "R2: 0.951251,   RMSE: 0.000723\n",
      "R2: 0.942896,   RMSE: 0.000832\n",
      "R2: 0.934433,   RMSE: 0.000939\n",
      "R2: 0.924390,   RMSE: 0.001066\n",
      "R2: 0.928859,   RMSE: 0.000988\n",
      "R2: 0.903604,   RMSE: 0.001319\n",
      "R2: 0.897875,   RMSE: 0.001378\n",
      "R2: 0.912795,   RMSE: 0.001161\n",
      "R2: 0.907639,   RMSE: 0.001214\n",
      "R2: 0.906315,   RMSE: 0.001216\n",
      "R2: 0.906141,   RMSE: 0.001203\n",
      "R2: 0.889840,   RMSE: 0.001395\n",
      "R2: 0.904337,   RMSE: 0.001198\n",
      "R2: 0.896243,   RMSE: 0.001285\n",
      "R2: 0.897422,   RMSE: 0.001257\n",
      "R2: 0.871973,   RMSE: 0.001552\n",
      "R2: 0.896845,   RMSE: 0.001238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for i in range(0,20):\n",
    "    r2_SO = r2_score(SO_real[:,i], SOf[:,i])\n",
    "    rmse_SO = mean_squared_error(SO_real[:,i], SOf[:,i])\n",
    "    print( \"R2: {0:f},   RMSE: {1:f}\".format(r2_SO, rmse_SO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 1\n",
      "Timestep 2\n",
      "Timestep 3\n",
      "Timestep 4\n",
      "Timestep 5\n",
      "Timestep 6\n",
      "Timestep 7\n",
      "Timestep 8\n",
      "Timestep 9\n",
      "Timestep 10\n",
      "Timestep 11\n",
      "Timestep 12\n",
      "Timestep 13\n",
      "Timestep 14\n",
      "Timestep 15\n",
      "Timestep 16\n",
      "Timestep 17\n",
      "Timestep 18\n",
      "Timestep 19\n",
      "Timestep 20\n"
     ]
    }
   ],
   "source": [
    "Diff = np.absolute(SOf - SO_real)\n",
    "\n",
    "for i in range(0,n_models):\n",
    "    SO_t = Diff[:,i].reshape((nx*ny,nz), order='F')\n",
    "    SO_L = SO_t[:, (Layer-1):Layer]\n",
    "    TT = SO_L.reshape((nx,ny), order ='F')\n",
    "    \n",
    "    col_type = cm.get_cmap('cool', 256)\n",
    "    newcolors = col_type(np.linspace(0, 1, 10000))\n",
    "    white = np.array([1, 1, 1, 1])\n",
    "    newcolors[:1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "    print('Timestep '+str(i+1))\n",
    "    #plot_examples([col_type, newcmp], TT, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_real_SO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-0d0b1141d096>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m    \u001b[1;31m# enter the timestep you want to see the error histogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdiffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_real_SO\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mSOpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my_real_SO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#                                                    bar opacity      the bigger, the more splits on x axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_real_SO' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "r = 1    # enter the timestep you want to see the error histogram\n",
    "differ = ((y_real_SO - SOpred)/y_real_SO)[:,r-1:r]\n",
    "\n",
    "#                                                    bar opacity      the bigger, the more splits on x axis\n",
    "#plt.hist(Histo_SO, color = 'red', edgecolor = 'black', alpha=0.8,  bins = 40 )\n",
    "plt.hist(differ,  color = 'red', edgecolor = 'black', alpha=0.8,  bins = 200 )\n",
    "plt.axvline(differ.mean(), color='k', linestyle='dashed', linewidth=2)\n",
    "\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "plt.text(differ.mean()*1.1, max_ylim*1, '  Mean: {:.5f}'.format(differ.mean()))\n",
    "\n",
    "\n",
    "plt.xlabel(\"Percentage error (%)\")\n",
    "plt.ylabel(\"Number of grids\")\n",
    "plt.xlim([-0.2, 0.2])    #change it depend on the ranges\n",
    "plt.ylim([0, 12000])    #change it depend on the ranges\n",
    "\n",
    "# this line is to show the y axis in K\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, pos: '%.0fk' % (y * 1e-3)))\n",
    "\n",
    "plt.savefig(\"Histogram-P.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted Output at different timesteps for P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 1\n",
      "Timestep 2\n",
      "Timestep 3\n",
      "Timestep 4\n",
      "Timestep 5\n",
      "Timestep 6\n",
      "Timestep 7\n",
      "Timestep 8\n",
      "Timestep 9\n",
      "Timestep 10\n",
      "Timestep 11\n",
      "Timestep 12\n",
      "Timestep 13\n",
      "Timestep 14\n",
      "Timestep 15\n",
      "Timestep 16\n",
      "Timestep 17\n",
      "Timestep 18\n",
      "Timestep 19\n",
      "Timestep 20\n"
     ]
    }
   ],
   "source": [
    "Layer = 1\n",
    "\n",
    "for i in range(0,n_models):\n",
    "    P_t = Pf[:,i].reshape((nx*ny,nz), order='F')\n",
    "    P_L = P_t[:, (Layer-1):Layer]\n",
    "    RR = P_L.reshape((nx,ny), order ='F')\n",
    "    \n",
    "    col_type = cm.get_cmap('rainbow', 256)\n",
    "    newcolors = col_type(np.linspace(0, 1, 1000))\n",
    "    #white = np.array([1, 1, 1, 1])\n",
    "    #newcolors[:1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "    print('Timestep '+str(i+1))\n",
    "    #plot_examples([col_type, newcmp], RR, 180, 280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.075207,   RMSE: 27842.624375\n",
      "R2: 0.072265,   RMSE: 28588.879328\n",
      "R2: 0.071397,   RMSE: 28862.555440\n",
      "R2: 0.070992,   RMSE: 29000.290823\n",
      "R2: 0.071234,   RMSE: 29064.361802\n",
      "R2: 0.071657,   RMSE: 29087.279899\n",
      "R2: 0.071999,   RMSE: 29101.383758\n",
      "R2: 0.072331,   RMSE: 29111.795874\n",
      "R2: 0.072496,   RMSE: 29123.240822\n",
      "R2: 0.072704,   RMSE: 29130.601603\n",
      "R2: 0.072886,   RMSE: 29139.630350\n",
      "R2: 0.073209,   RMSE: 29140.836387\n",
      "R2: 0.073386,   RMSE: 29145.146230\n",
      "R2: 0.073508,   RMSE: 29150.088937\n",
      "R2: 0.073657,   RMSE: 29153.124809\n",
      "R2: 0.073824,   RMSE: 29156.913085\n",
      "R2: 0.073797,   RMSE: 29164.366293\n",
      "R2: 0.074027,   RMSE: 29162.889685\n",
      "R2: 0.074093,   RMSE: 29166.116848\n",
      "R2: 0.074268,   RMSE: 29165.811949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for i in range(0,20):\n",
    "    r2_P = r2_score(P_real[:,i], Pf[:,i])\n",
    "    rmse_P = mean_squared_error(P_real[:,i], Pf[:,i])\n",
    "    print( \"R2: {0:f},   RMSE: {1:f}\".format(r2_P, rmse_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Diff = np.absolute(Pf - P_real)\n",
    "print(Diff.shape)\n",
    "max1 = np.max(Diff)\n",
    "print(max1)\n",
    "\n",
    "for i in range(0,n_models):\n",
    "    P_t = Diff[:,i].reshape((nx*ny,nz), order='F')\n",
    "    P_L = P_t[:, (Layer-1):Layer]\n",
    "    YY = P_L.reshape((nx,ny), order ='F')\n",
    "    \n",
    "    col_type = cm.get_cmap('cool', 256)\n",
    "    newcolors = col_type(np.linspace(0, 1, 10000))\n",
    "    white = np.array([1, 1, 1, 1])\n",
    "    newcolors[:1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "    print('Timestep '+str(i+1))\n",
    "    #plot_examples([col_type, newcmp], YY, 0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "r = 1    # enter the timestep you want to see the error histogram\n",
    "differ_P = ((y_real_P - Ppred)/y_real_P)[:,r-1:r]\n",
    "\n",
    "#                                                    bar opacity      the bigger, the more splits on x axis\n",
    "#plt.hist(Histo_SO, color = 'red', edgecolor = 'black', alpha=0.8,  bins = 40 )\n",
    "plt.hist(differ_P,  color = 'red', edgecolor = 'black', alpha=0.8,  bins = 100 )\n",
    "plt.axvline(differ_P.mean(), color='k', linestyle='dashed', linewidth=2)\n",
    "\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "plt.text(differ_P.mean()*1.1, max_ylim*1, '  Mean: {:.5f}'.format(differ_P.mean()))\n",
    "\n",
    "\n",
    "plt.xlabel(\"Percentage error (%)\")\n",
    "plt.ylabel(\"Number of grids\")\n",
    "plt.xlim([-0.03, 0.03])    #change it depend on the ranges\n",
    "plt.ylim([0, 14000])    #change it depend on the ranges\n",
    "\n",
    "# this line is to show the y axis in K\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, pos: '%.0fk' % (y * 1e-3)))\n",
    "\n",
    "#plt.savefig(\"Histogram-P.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Well Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distance = pd.read_csv('C:/Users/pymnb/Downloads/VOLVE/15/Features/distances.csv').drop_duplicates().reset_index(drop=True)\n",
    "ave_static = pd.read_csv('C:/Users/pymnb/Downloads/VOLVE/15/Features/average static.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tiers = pd.read_csv('C:/Users/pymnb/Downloads/WAG Case/18/Features/index_tiers.csv', header=None)\n",
    "\n",
    "def AVERAGE(dynamic_feature, timestep_no, surrounding_index):\n",
    "    \n",
    "    var_slice_timestep = dynamic_feature[actives_r][:,:,(timestep_no-1)]\n",
    "    \n",
    "    var_slice_time_surr = var_slice_timestep[surrounding_index]\n",
    "\n",
    "    average = np.reshape(np.average(var_slice_time_surr), (1,1))\n",
    "    \n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the average SO, P for Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3 = pd.DataFrame()\n",
    "\n",
    "for i in range(21):\n",
    "    z1 = np.zeros((1,1))\n",
    "    z2 = np.zeros((1,1))\n",
    "    for j in range(25):\n",
    "        T = index_tiers.iloc[:,j:j+1].dropna().astype(int)\n",
    "        ave1 = AVERAGE(SOf, i, T)\n",
    "        ave2 = AVERAGE(Pf, i, T)\n",
    "        result1 = np.concatenate([z1, ave1])\n",
    "        result2 = np.concatenate([z2, ave2])\n",
    "        z1 = result1\n",
    "        z2 = result2\n",
    "        \n",
    "    SO_tiers = pd.DataFrame(z1[1:].reshape(1,25))\n",
    "    P_tiers  = pd.DataFrame(z2[1:].reshape(1,25))\n",
    "    Tiers = pd.concat([SO_tiers, P_tiers], axis=1)\n",
    "    Tiers_alltimes = pd.concat([z3, Tiers])\n",
    "    z3 = Tiers_alltimes\n",
    "Tier_alltime_allwell = z3.reset_index(drop=True)\n",
    "Tier_alltime_allwell.columns = range(Tier_alltime_allwell.columns.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tier_alltime_E3H = pd.concat([Tier_alltime_allwell.iloc[:, 0:5], Tier_alltime_allwell.iloc[:, 25:30]], axis=1)\n",
    "Tier_alltime_E3H.columns = ['SO_T1', 'SO_T2', 'SO_T3', 'SO_T4', 'SO_T5', 'P_T1', 'P_T2', 'P_T3', 'P_T4', 'P_T5']\n",
    "\n",
    "Tier_alltime_E2H = pd.concat([Tier_alltime_allwell.iloc[:, 5:10], Tier_alltime_allwell.iloc[:, 30:35]], axis=1)\n",
    "Tier_alltime_E2H.columns = ['SO_T1', 'SO_T2', 'SO_T3', 'SO_T4', 'SO_T5', 'P_T1', 'P_T2', 'P_T3', 'P_T4', 'P_T5']\n",
    "\n",
    "Tier_alltime_E3AH = pd.concat([Tier_alltime_allwell.iloc[:, 10:15], Tier_alltime_allwell.iloc[:, 35:40]], axis=1)\n",
    "Tier_alltime_E3AH.columns = ['SO_T1', 'SO_T2', 'SO_T3', 'SO_T4', 'SO_T5', 'P_T1', 'P_T2', 'P_T3', 'P_T4', 'P_T5']\n",
    "\n",
    "Tier_alltime_F1H = pd.concat([Tier_alltime_allwell.iloc[:, 15:20], Tier_alltime_allwell.iloc[:, 40:45]], axis=1)\n",
    "Tier_alltime_F1H.columns = ['SO_T1', 'SO_T2', 'SO_T3', 'SO_T4', 'SO_T5', 'P_T1', 'P_T2', 'P_T3', 'P_T4', 'P_T5']\n",
    "\n",
    "Tier_alltime_F3H = pd.concat([Tier_alltime_allwell.iloc[:, 20:25], Tier_alltime_allwell.iloc[:, 45:50]], axis=1)\n",
    "Tier_alltime_F3H.columns = ['SO_T1', 'SO_T2', 'SO_T3', 'SO_T4', 'SO_T5', 'P_T1', 'P_T2', 'P_T3', 'P_T4', 'P_T5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the final input array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_E3H = pd.concat([time_ind, well_ind1, df_lhs, D_E3H , Tier_alltime_E3H], axis=1).reset_index(drop=True)\n",
    "inputs_E2H = pd.concat([time_ind, well_ind2, df_lhs, D_E2H , Tier_alltime_E2H], axis=1).reset_index(drop=True)\n",
    "inputs_E3AH= pd.concat([time_ind, well_ind3, df_lhs, D_E3AH, Tier_alltime_E3AH],axis=1).reset_index(drop=True)\n",
    "inputs_F1H = pd.concat([time_ind, well_ind4, df_lhs, D_F1H , Tier_alltime_F1H], axis=1).reset_index(drop=True)\n",
    "inputs_F3H = pd.concat([time_ind, well_ind5, df_lhs, D_F3H , Tier_alltime_F3H], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4141800.484]\n",
      " [4154634.534]\n",
      " [4182241.18 ]\n",
      " [4202947.848]\n",
      " [4216555.5  ]\n",
      " [4238739.266]\n",
      " [4259649.408]\n",
      " [4275258.468]\n",
      " [4286299.134]\n",
      " [4300409.676]\n",
      " [4315016.052]\n",
      " [4324808.686]\n",
      " [4332628.644]\n",
      " [4348646.394]\n",
      " [4360129.63 ]\n",
      " [4368572.028]\n",
      " [4376977.618]\n",
      " [4380135.684]\n",
      " [4393601.408]\n",
      " [4394195.528]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "well_ind = 1\n",
    "\n",
    "#real_prod_BT = pd.read_fwf('C:/Users/pymnb/Downloads/VOLVE/15/Features/BT2-prod.txt', header=None)\n",
    "#real_prod_BT.columns = [\"OPT(11B)\", \"OPT(12)\", \"OPT(14)\", \"OPT(1C)\", \"OPT(15C)\"]\n",
    "\n",
    "loaded_model = joblib.load('C:/Users/pymnb/Downloads/VOLVE/15/Well models/opt7.sav')\n",
    "\n",
    "z5 = np.zeros((1,1))\n",
    "for t in range(1,21):\n",
    "    input_vector = pd.DataFrame(np.array([t, well_ind, 1937, 273, 3720, 2257, 4777])).transpose()\n",
    "    result = loaded_model.predict(input_vector).reshape(1,1)\n",
    "    pred_well = np.concatenate([z5, result])\n",
    "    z5 = pred_well\n",
    "opr_pred = z5[1:]\n",
    "\n",
    "print(opr_pred)\n",
    "         \n",
    "#r2_test = r2_score(real_prod_BT['WPT(E3AH)'], wpr_pred)\n",
    "#print(r2_test)\n",
    "#\n",
    "#plt.clf()\n",
    "#fig, ax = plt.subplots(3,4, figsize=(17,13))\n",
    "#\n",
    "##\n",
    "#ax[0,0].scatter(x = np.arange(21), y = real_prod_BT['WPT(E3AH)'])\n",
    "##ax[0,0].scatter(x = np.arange(21), y = wpr_pred)\n",
    "##plt.xlabel(\"Living Area Above Ground\")\n",
    "##plt.ylabel(\"House Price\")\n",
    "#\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2260365.376]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "well = 1\n",
    "\n",
    "A = pd.DataFrame(np.array([20, 4, 4399, 2605, 308, 4149, 4782])).transpose()\n",
    "loaded_model = joblib.load('C:/Users/pymnb/Downloads/VOLVE/15/Well models/opt7.sav')\n",
    "predicted = loaded_model.predict(A)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "r2 = r2_score(Actual, Pred)\n",
    "rmse = mean_squared_error(Actual, Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9368775840131484\n",
      "31802642.49\n"
     ]
    }
   ],
   "source": [
    "print(r2)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results by manual calculation:\n",
      "MAE: 4606.91\n",
      "MSE: 31802642.49\n",
      "RMSE: 5639.383165737189\n",
      "R-Squared: [1.02212481]\n"
     ]
    }
   ],
   "source": [
    "d = Actual - Pred\n",
    "mse_f = np.mean(d**2)\n",
    "mae_f = np.mean(abs(d))\n",
    "rmse_f = np.sqrt(mse_f)\n",
    "r2_f = 1-(sum(d**2)/sum((Actual-np.mean(Actual))**2))\n",
    "\n",
    "print(\"Results by manual calculation:\")\n",
    "print(\"MAE:\",mae_f)\n",
    "print(\"MSE:\", mse_f)\n",
    "print(\"RMSE:\", rmse_f)\n",
    "print(\"R-Squared:\", r2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of sklearn.metrics:\n",
      "MAE: 4606.91\n",
      "MSE: 31802642.49\n",
      "RMSE: 5639.383165737189\n",
      "R-Squared: 0.9368775840131484\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "mae = metrics.mean_absolute_error(Actual, Pred)\n",
    "mse = metrics.mean_squared_error(Actual, Pred)\n",
    "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
    "r2 = metrics.r2_score(Actual,Pred)\n",
    "\n",
    "print(\"Results of sklearn.metrics:\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-Squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
